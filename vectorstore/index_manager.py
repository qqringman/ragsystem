import os
import warnings

# ç¦ç”¨ ChromaDB é™æ¸¬
os.environ["CHROMA_TELEMETRY"] = "false"
os.environ["ANONYMIZED_TELEMETRY"] = "false"

# å˜—è©¦ä½¿ç”¨æ–°ç‰ˆæœ¬çš„ Chroma
try:
    from langchain_chroma import Chroma
    print("âœ… ä½¿ç”¨ langchain-chroma åŒ…")
except ImportError:
    # å¦‚æœæ–°åŒ…ä¸å­˜åœ¨ï¼Œä½¿ç”¨èˆŠç‰ˆæœ¬ä½†ç¦ç”¨è­¦å‘Š
    warnings.filterwarnings("ignore", category=DeprecationWarning, module="langchain_community.vectorstores")
    from langchain_community.vectorstores import Chroma
    print("âš ï¸  ä½¿ç”¨èˆŠç‰ˆ Chroma (langchain_community)")

from langchain_community.vectorstores import Qdrant, Redis
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_huggingface import HuggingFaceEmbeddings
from config import get_config

# ç¦ç”¨å…¶ä»–è­¦å‘Š
warnings.filterwarnings("ignore", message=".*torch.classes.*")
warnings.filterwarnings("ignore", message=".*telemetry.*")

def get_vectorstore():
    """
    ç²å–å‘é‡è³‡æ–™åº«å¯¦ä¾‹
    
    Returns:
        å‘é‡è³‡æ–™åº«å¯¦ä¾‹ (Chroma, Redis æˆ– Qdrant)
    """
    vec_type = get_config("VECTOR_DB", "chroma").lower()
    embedding = get_embeddings()

    if vec_type == "chroma":
        persist_dir = get_config("CHROMA_PERSIST_DIR", "vector_db/chroma")
        
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        os.makedirs(persist_dir, exist_ok=True)
        
        try:
            # å˜—è©¦ä½¿ç”¨å®¢æˆ¶ç«¯è¨­å®šä¾†é¿å…é™æ¸¬å•é¡Œ
            import chromadb
            from chromadb.config import Settings
            
            # å‰µå»ºå®¢æˆ¶ç«¯è¨­å®š
            client_settings = Settings(
                anonymized_telemetry=False,
                telemetry=False,
                persist_directory=persist_dir
            )
            
            # å‰µå»º Chroma å¯¦ä¾‹
            return Chroma(
                embedding_function=embedding,
                persist_directory=persist_dir,
                client_settings=client_settings,
                collection_metadata={"hnsw:space": "cosine"}
            )
        except Exception as e:
            print(f"âš ï¸  ä½¿ç”¨é è¨­ Chroma è¨­å®š: {e}")
            # å¦‚æœå¤±æ•—ï¼Œä½¿ç”¨ç°¡å–®é…ç½®
            return Chroma(
                embedding_function=embedding,
                persist_directory=persist_dir
            )
            
    elif vec_type == "redis":
        redis_url = get_config("REDIS_URL", "redis://localhost:6379")
        index_name = get_config("REDIS_INDEX_NAME", "rag_index")
        return Redis(
            embedding_function=embedding, 
            index_name=index_name, 
            redis_url=redis_url
        )
        
    elif vec_type == "qdrant":
        qdrant_url = get_config("QDRANT_URL", "http://localhost:6333")
        collection_name = get_config("QDRANT_COLLECTION", "rag_data")
        return Qdrant(
            collection_name=collection_name, 
            embeddings=embedding, 
            location=qdrant_url
        )
    else:
        raise ValueError(f"Unsupported VECTOR_DB: {vec_type}")

def get_embeddings():
    """
    ç²å–åµŒå…¥æ¨¡å‹
    
    Returns:
        åµŒå…¥æ¨¡å‹å¯¦ä¾‹
    """
    provider = get_config("EMBED_PROVIDER", "huggingface")  # é è¨­ä½¿ç”¨ huggingface
    
    if provider == "openai":
        api_key = get_config("OPENAI_API_KEY")
        if not api_key or api_key.startswith("sk-your"):
            print("âš ï¸  ç„¡æ•ˆçš„ OpenAI API keyï¼Œè‡ªå‹•åˆ‡æ›åˆ° HuggingFace åµŒå…¥æ¨¡å‹")
            provider = "huggingface"
        else:
            return OpenAIEmbeddings(openai_api_key=api_key)
    
    # é è¨­ä½¿ç”¨ HuggingFaceï¼ˆå…è²»ä¸”ä¸éœ€è¦ API keyï¼‰
    print("ğŸ¤— ä½¿ç”¨ HuggingFace åµŒå…¥æ¨¡å‹ï¼ˆå…è²»ï¼‰")
    model_name = get_config("HUGGINGFACE_MODEL", "sentence-transformers/all-MiniLM-L6-v2")
    
    # è¨­å®šä¾†é¿å…è­¦å‘Š
    return HuggingFaceEmbeddings(
        model_name=model_name,
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )