# ğŸ³ Docker Compose å•Ÿå‹• Ollama æœå‹™

## å•é¡Œèªªæ˜

`ollama` æœå‹™åœ¨ `docker-compose.yml` ä¸­è¢«è¨­å®šç‚ºå¯é¸æœå‹™ï¼ˆä½¿ç”¨ profilesï¼‰ï¼Œæ‰€ä»¥é è¨­ä¸æœƒå•Ÿå‹•ã€‚

## è§£æ±ºæ–¹æ¡ˆ

### æ–¹æ³• 1ï¼šä½¿ç”¨ Profile å•Ÿå‹•ï¼ˆæ¨è–¦ï¼‰

```bash
# å•Ÿå‹•åŒ…å« ollama çš„æœå‹™
docker-compose --profile ollama up -d

# æª¢æŸ¥æœå‹™ç‹€æ…‹
docker-compose ps

# ç„¶å¾Œä¸‹è¼‰æ¨¡å‹
docker-compose exec ollama ollama pull llama3
```

### æ–¹æ³• 2ï¼šä¿®æ”¹ docker-compose.yml

ç§»é™¤ ollama æœå‹™çš„ profiles è¨­å®šï¼Œè®“å®ƒé è¨­å•Ÿå‹•ï¼š

```yaml
# æ‰¾åˆ° ollama æœå‹™éƒ¨åˆ†ï¼Œç§»é™¤æˆ–è¨»è§£ profiles
ollama:
  image: ollama/ollama:latest
  container_name: rag-ollama
  ports:
    - "11434:11434"
  volumes:
    - ollama_data:/root/.ollama
  networks:
    - rag-network
  restart: unless-stopped
  # profiles:      # è¨»è§£æˆ–åˆªé™¤é€™å…©è¡Œ
  #   - ollama
```

ç„¶å¾Œé‡æ–°å•Ÿå‹•ï¼š
```bash
docker-compose up -d ollama
```

### æ–¹æ³• 3ï¼šå–®ç¨å•Ÿå‹• Ollama å®¹å™¨

```bash
# ç›´æ¥é‹è¡Œ ollama å®¹å™¨
docker run -d \
  --name ollama \
  -p 11434:11434 \
  -v ollama_data:/root/.ollama \
  ollama/ollama:latest

# ä¸‹è¼‰æ¨¡å‹
docker exec ollama ollama pull llama3

# æª¢æŸ¥æ¨¡å‹åˆ—è¡¨
docker exec ollama ollama list
```

### æ–¹æ³• 4ï¼šåœ¨ä¸»æ©Ÿä¸Šå®‰è£ Ollamaï¼ˆæœ€ç°¡å–®ï¼‰

å¦‚æœä¸æƒ³ä½¿ç”¨ Docker ä¸­çš„ Ollamaï¼š

```bash
# é€€å‡º docker ç›®éŒ„
cd ..

# åœ¨ä¸»æ©Ÿä¸Šå®‰è£ Ollama
curl -fsSL https://ollama.com/install.sh | sh

# å•Ÿå‹• Ollama æœå‹™
ollama serve &

# ä¸‹è¼‰æ¨¡å‹
ollama pull llama3

# æª¢æŸ¥æ˜¯å¦æ­£å¸¸
ollama list
```

ç„¶å¾Œä¿®æ”¹ `.env`ï¼š
```bash
# å¦‚æœä½¿ç”¨ä¸»æ©Ÿçš„ Ollama
OLLAMA_BASE_URL=http://host.docker.internal:11434  # Docker å…§éƒ¨è¨ªå•ä¸»æ©Ÿ

# æˆ–å¦‚æœä¸ä½¿ç”¨ Docker é‹è¡Œ RAG
OLLAMA_BASE_URL=http://localhost:11434
```

## ğŸ” æª¢æŸ¥æœå‹™ç‹€æ…‹

### æª¢æŸ¥ Docker æœå‹™
```bash
# æŸ¥çœ‹æ‰€æœ‰æœå‹™ï¼ˆåŒ…æ‹¬ profiles ä¸­çš„ï¼‰
docker-compose config --profiles

# æŸ¥çœ‹é‹è¡Œä¸­çš„æœå‹™
docker-compose ps

# æŸ¥çœ‹ç‰¹å®š profile çš„æœå‹™
docker-compose --profile ollama ps
```

### æ¸¬è©¦ Ollama é€£æ¥
```bash
# å¦‚æœ Ollama åœ¨é‹è¡Œï¼Œæ¸¬è©¦ API
curl http://localhost:11434/api/tags

# æ‡‰è©²è¿”å› JSON æ ¼å¼çš„æ¨¡å‹åˆ—è¡¨
```

## ğŸ“‹ å®Œæ•´çš„å•Ÿå‹•æµç¨‹

### ä½¿ç”¨ Docker Compose + Ollamaï¼š

```bash
# 1. å•Ÿå‹•æ‰€æœ‰æœå‹™ï¼ˆåŒ…å« ollamaï¼‰
docker-compose --profile ollama up -d

# 2. ç­‰å¾…æœå‹™å•Ÿå‹•
sleep 10

# 3. æª¢æŸ¥æœå‹™ç‹€æ…‹
docker-compose ps

# 4. ä¸‹è¼‰ llama3 æ¨¡å‹
docker-compose exec ollama ollama pull llama3

# 5. é©—è­‰æ¨¡å‹
docker-compose exec ollama ollama list

# 6. æ¸¬è©¦æ¨¡å‹
docker-compose exec ollama ollama run llama3 "Hello, how are you?"
```

### æˆ–ä½¿ç”¨æœ¬åœ° Ollamaï¼ˆæ›´ç°¡å–®ï¼‰ï¼š

```bash
# 1. å®‰è£ Ollamaï¼ˆå¦‚æœé‚„æ²’å®‰è£ï¼‰
curl -fsSL https://ollama.com/install.sh | sh

# 2. å•Ÿå‹• Ollama
ollama serve &

# 3. ä¸‹è¼‰æ¨¡å‹
ollama pull llama3

# 4. å•Ÿå‹• RAG ç³»çµ±ï¼ˆä¸ä½¿ç”¨ ollama å®¹å™¨ï¼‰
docker-compose up -d app postgres redis

# æˆ–ç›´æ¥åœ¨æœ¬åœ°é‹è¡Œ
streamlit run app.py
```

## ğŸ’¡ å»ºè­°

1. **é–‹ç™¼ç’°å¢ƒ**ï¼šä½¿ç”¨æœ¬åœ°å®‰è£çš„ Ollama æ›´æ–¹ä¾¿
2. **ç”Ÿç”¢ç’°å¢ƒ**ï¼šä½¿ç”¨ Docker å®¹å™¨åŒ–éƒ¨ç½²
3. **è³‡æºè€ƒé‡**ï¼šOllama éœ€è¦è¼ƒå¤šè³‡æºï¼Œç¢ºä¿æœ‰è¶³å¤ çš„ RAM

## ğŸ”§ æ•…éšœæ’é™¤

### å¦‚æœ Ollama å®¹å™¨å•Ÿå‹•å¤±æ•—ï¼š

1. **æª¢æŸ¥ç«¯å£å ç”¨**ï¼š
   ```bash
   lsof -i :11434
   ```

2. **æª¢æŸ¥ Docker è³‡æº**ï¼š
   ```bash
   docker system df
   docker system prune  # æ¸…ç†ä¸ç”¨çš„è³‡æº
   ```

3. **æŸ¥çœ‹å®¹å™¨æ—¥èªŒ**ï¼š
   ```bash
   docker-compose --profile ollama logs ollama
   ```

### å¦‚æœæ¨¡å‹ä¸‹è¼‰å¤±æ•—ï¼š

1. **æª¢æŸ¥ç¶²è·¯é€£æ¥**
2. **ç¢ºä¿æœ‰è¶³å¤ çš„ç¡¬ç¢Ÿç©ºé–“**ï¼ˆllama3 ç´„éœ€ 5GBï¼‰
3. **å˜—è©¦ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹**ï¼š
   ```bash
   ollama pull gemma:2b  # åªéœ€è¦ç´„ 1.5GB
   ```

---

é¸æ“‡æœ€é©åˆä½ çš„æ–¹æ³•ï¼Œé€šå¸¸**æ–¹æ³• 4**ï¼ˆåœ¨ä¸»æ©Ÿä¸Šå®‰è£ Ollamaï¼‰æ˜¯æœ€ç°¡å–®çš„ã€‚